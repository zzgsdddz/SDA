---
title: "SDA Group Submission Assignment Assign4"
subtitle: "Group Gr18" 
author: "MengliFeng (2720589) and PepijnVanOostveen (2801582)"
output: 
  pdf_document:
    keep_tex: true
header-includes:
  - \usepackage{fvextra}
  - \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
---

# Exercise 1
```{r}
library(carData)
Davis <- Davis[-12, ]
head(Davis)
```
## a.
```{r}
# Load necessary libraries
library(ggplot2)

# Split data by sex
Davis_M <- subset(Davis, sex == "M")
Davis_F <- subset(Davis, sex == "F")

# Set up plotting area
par(mfrow = c(2, 2))

# Histograms for height distributions (scaled to density)
hist(Davis_M$height, probability = TRUE, main = "Height Distribution (Males)", xlab = "Height (cm)", col = "blue")
hist(Davis_F$height, probability = TRUE, main = "Height Distribution (Females)", xlab = "Height (cm)", col = "red")

# QQ-plots for normality check
qqnorm(Davis_M$height, main = "QQ-Plot (Males)")
qqline(Davis_M$height)

qqnorm(Davis_F$height, main = "QQ-Plot (Females)")
qqline(Davis_F$height)

# Normality test using Shapiro-Wilk
shapiro.test(Davis_M$height)
shapiro.test(Davis_F$height)
```
from both the histograms and the qq-plots, we can see the distributions of heights of both male and female are both close to normal distribution. From the histograms, we can observe a subtlety that heights of males have more mass below the mean and vice versa for weights of females.

From Shapiro-Wilk test results, the null hypothesis is not rejected.

? what's about the rounded heights

## b.
```{r}
# Set seed for reproducibility
set.seed(1234)

# Function to compute the difference in means
mean_diff <- function(data) {
  mean(data$height[data$sex == "M"]) - mean(data$height[data$sex == "F"])
}

# **Empirical Bootstrap**
n_bootstrap <- 1000  # Number of bootstrap samples
boot_diffs_empirical <- replicate(n_bootstrap, {
  resample_M <- sample(Davis_M$height, replace = TRUE)
  resample_F <- sample(Davis_F$height, replace = TRUE)
  mean(resample_M) - mean(resample_F)
})

# Standard deviation of bootstrap samples (empirical bootstrap)
sd_empirical <- sd(boot_diffs_empirical)

# **Parametric Bootstrap (assuming normality)**
parametric_boot_diffs <- replicate(n_bootstrap, {
  resample_M <- rnorm(length(Davis_M$height), mean(Davis_M$height), sd(Davis_M$height))
  resample_F <- rnorm(length(Davis_F$height), mean(Davis_F$height), sd(Davis_F$height))
  mean(resample_M) - mean(resample_F)
})

# Standard deviation of bootstrap samples (parametric bootstrap)
sd_parametric <- sd(parametric_boot_diffs)

# Print results
cat("Empirical Bootstrap SD:", sd_empirical, "\n")
cat("Parametric Bootstrap SD:", sd_parametric, "\n")
```

## c.
```{r}
# Given values
mu_M <- 177.8
mu_F <- 164.6
sigma_M <- 6.5
sigma_F <- 5.5
n_M <- length(Davis_M$height)
n_F <- length(Davis_F$height)

# Compute theoretical standard deviation
theoretical_sd <- sqrt((sigma_M^2 / n_M) + (sigma_F^2 / n_F))
cat("Theoretical SD:", theoretical_sd, "\n")

# Compare theoretical vs. bootstrap estimates
comparison <- data.frame(
  Method = c("Empirical Bootstrap", "Parametric Bootstrap", "Theoretical"),
  SD = c(sd_empirical, sd_parametric, theoretical_sd)
)

print(comparison)
```
the parametric boostrap estimation of the sd of the mean difference is closer to the theoretical value

## d.
```{r}
# Set boundaries for uniform distribution
min_M <- min(Davis_M$height)
max_M <- max(Davis_M$height)
min_F <- min(Davis_F$height)
max_F <- max(Davis_F$height)

# Perform parametric bootstrap with uniform distribution
uniform_boot_diffs <- replicate(n_bootstrap, {
  resample_M <- runif(n_M, min_M, max_M)
  resample_F <- runif(n_F, min_F, max_F)
  mean(resample_M) - mean(resample_F)
})

# Standard deviation of bootstrap samples (uniform distribution)
sd_uniform <- sd(uniform_boot_diffs)

cat("Uniform Bootstrap SD:", sd_uniform, "\n")

# Compare with theoretical standard deviation
comparison <- rbind(comparison, c("Uniform Bootstrap", sd_uniform))
print(comparison)
```


# Exercise 2
## a.
It is given that $$\tilde{D_n}=max_i max\left(\left| \frac{i-1}{n} - \Phi\left( \frac{X_{(i)}-\bar{X}}{S} \right)\right|, \left| \frac{i}{n} - \Phi\left(\frac{X_{(i)}-\bar{X}}{S}\right) \right|\right)$$ 

This depends on $F$ by using $\frac{X_{(i)}-\bar{X}}{S}$ and the null hypothesis states that $X_{(i)}\sim N(\bar{X},S)$. Thus $X_{(i)}-\bar{X}\sim N(0,S)$ and finally we define $Z_{(i)}=\frac{X_{(i)}-\bar{X}}{S}\sim N(0,1)$. Substituting this in our original equation we get:
$$\tilde{D_n}=max_i max\left(\left| \frac{i-1}{n} - \Phi\left(Z_{(i)} \right)\right|, \left| \frac{i}{n} - \Phi\left(Z_{(i)}\right) \right|\right)$$ 
Which shows that under the null, $\tilde{D}_n$ is independent of the location and scale parameters since $Z_{(i)}$ is independent of them.

## b.
```{r}
# Load the data
data(morley)
head(morley)
l_speed <- morley$Speed

# Calculate the mean and standard dev
m_speed <- mean(l_speed)
sd_speed <- sd(l_speed)

# run ks.test
ks_result <- ks.test(l_speed, "pnorm", mean = m_speed, sd = sd_speed)

# Extract D_n and the p-value
D_n <- ks_result$statistic
p_value <- ks_result$p.value
print(D_n)
print(p_value)
```
The p-value (0.4895616) is more than the significance level of 0.05 and thus we don't reject the null hypothesis that the data follows a normal distribution.
The p-value isn't reliable since the Kolmogorov-Smirnov assumes that we now the parameters of the distribution, but we had to estimate them using the sample mean and standard deviation.
(R also gives the warning "Warning: ties should not be present for the one-sample Kolmogorov-Smirnov test" which means that some values in the data repeat which and that shouldn't happen since the test is made for a continuous distribution.)


## c.
```{r}
set.seed(1234)

n <- length(l_speed)
B <- 1000
Dn_star <- numeric(B)

for (i in 1:B) {
  # Generate bootstrap sample from N(m_speed, sd_speed^2)
  bootstrap_sample <- rnorm(n, mean = m_speed, sd = sd_speed)

  # Calculate the mean and standard dev
  m_star <- mean(bootstrap_sample)
  sd_star <- sd(bootstrap_sample)
  
  # run ks.test
  ks_star <- ks.test(bootstrap_sample, "pnorm", mean = m_star, sd = sd_star)
  Dn_star[i] <- ks_star$statistic
}

# compute p-value using the bootstrap distribution
p_value_bootstrap <- mean(Dn_star >= D_n)

print(p_value_bootstrap)
```

## d.
There is a big difference between the p-values in b and c. b results in a p-value of 0.4895616 and the bootstrap method in c results in a p-value of 0.078. This difference of 0.411 is very big, but still not large enough to result in different test decisions as the result from c is still above the significance level of 0.05.
The final conclusion is that both tests result in not rejecting the null hypothesis and thus not having enough evidence that the data doesn't follow a normal distribution.
